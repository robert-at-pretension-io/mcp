Using Different Model Providers in LangChain.js
LangChain.js makes it easy to work with multiple LLM providers through dedicated integration packages. Here's how to set up and use different providers:
Overall Structure
LangChain.js has separated its provider integrations into individual packages:

Core Package: @langchain/core - Contains base abstractions and the LangChain Expression Language
Provider-Specific Packages: For example, @langchain/openai, @langchain/anthropic, etc.

Installation Process
To use a specific provider, you need to install both the core package and the provider-specific package:
bash# For OpenAI models
npm install @langchain/core @langchain/openai

# For Anthropic models
npm install @langchain/core @langchain/anthropic

# For Google models
npm install @langchain/core @langchain/google-genai

# For Mistral models
npm install @langchain/core @langchain/mistralai
Using Different Providers
1. OpenAI
javascriptimport { ChatOpenAI } from "@langchain/openai";

// API keys are loaded from environment variables by default (OPENAI_API_KEY)
const openaiModel = new ChatOpenAI({
  model: "gpt-4o",  // specify the model
  temperature: 0.7,  // control randomness
});

// Basic invocation
const response = await openaiModel.invoke("Tell me a short joke about programming.");

// Using with a system message and user message
const response = await openaiModel.invoke([
  { role: "system", content: "You are a helpful assistant that speaks like a pirate." },
  { role: "user", content: "Tell me about JavaScript." }
]);
2. Anthropic
javascriptimport { ChatAnthropic } from "@langchain/anthropic";

// API key from environment variable (ANTHROPIC_API_KEY)
const anthropicModel = new ChatAnthropic({
  model: "claude-3-opus-20240229",
  temperature: 0.5,
});

// Basic invocation
const response = await anthropicModel.invoke("What are three ways to improve code quality?");

// With system and user messages
const response = await anthropicModel.invoke([
  { role: "system", content: "You are a helpful programming tutor." },
  { role: "user", content: "Explain async/await in JavaScript." }
]);
3. Google AI (Gemini)
javascriptimport { ChatGoogleGenerativeAI } from "@langchain/google-genai";

// API key from environment variable (GOOGLE_API_KEY)
const googleModel = new ChatGoogleGenerativeAI({
  model: "gemini-pro",
  temperature: 0.3,
});

// Basic invocation
const response = await googleModel.invoke("What are the key features of Gemini Pro?");
4. Mistral AI
javascriptimport { ChatMistralAI } from "@langchain/mistralai";

// API key from environment variable (MISTRAL_API_KEY)
const mistralModel = new ChatMistralAI({
  model: "mistral-large-latest",
  temperature: 0.7,
});

const response = await mistralModel.invoke("Explain quantum computing in simple terms.");
5. Together AI (for accessing multiple open models)
javascriptimport { ChatTogetherAI } from "@langchain/community/chat_models/togetherai";

const togetherModel = new ChatTogetherAI({
  model: "meta-llama/Llama-2-70b-chat-hf",
  temperature: 0.7,
  // API key from environment variable (TOGETHER_API_KEY)
});

const response = await togetherModel.invoke("Tell me about the Llama 2 model.");
Using Multiple Providers in the Same Application
Here's how you can use multiple providers in the same application:
javascriptimport { ChatOpenAI } from "@langchain/openai";
import { ChatAnthropic } from "@langchain/anthropic";
import { ChatMistralAI } from "@langchain/mistralai";
import { ChatPromptTemplate } from "@langchain/core/prompts";

// Initialize models from different providers
const gpt4 = new ChatOpenAI({ model: "gpt-4o" });
const claude = new ChatAnthropic({ model: "claude-3-opus-20240229" });
const mistral = new ChatMistralAI({ model: "mistral-large-latest" });

// Create a shared prompt template
const prompt = ChatPromptTemplate.fromTemplate(
  "Compare and contrast {topic_a} and {topic_b} in a few paragraphs."
);

// Function to get responses from all models
async function compareResponses(topicA, topicB) {
  const formattedPrompt = await prompt.format({
    topic_a: topicA,
    topic_b: topicB,
  });
  
  // Call all models in parallel
  const [gpt4Response, claudeResponse, mistralResponse] = await Promise.all([
    gpt4.invoke(formattedPrompt),
    claude.invoke(formattedPrompt),
    mistral.invoke(formattedPrompt),
  ]);
  
  return {
    gpt4: gpt4Response.content,
    claude: claudeResponse.content,
    mistral: mistralResponse.content,
  };
}

// Usage
const results = await compareResponses("quantum computing", "classical computing");
console.log("GPT-4 response:", results.gpt4);
console.log("Claude response:", results.claude);
console.log("Mistral response:", results.mistral);
Environment Setup
For security, all providers expect API keys to be stored in environment variables:
javascript// In your .env file
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=...
MISTRAL_API_KEY=...
TOGETHER_API_KEY=...
You can also pass API keys directly in the constructor:
javascriptconst model = new ChatOpenAI({ 
  model: "gpt-4o",
  openAIApiKey: "your-api-key-here" // Not recommended for production code
});
Using a Model-Agnostic Approach
LangChain.js also supports a more abstract approach where you can swap models easily:
javascriptimport { ChatPromptTemplate } from "@langchain/core/prompts";
import { RunnableSequence } from "@langchain/core/runnables";

// Create a model variable that can be any provider
let model; 

// Set the model based on a configuration or parameter
function setModel(providerName) {
  switch(providerName) {
    case "openai":
      model = new ChatOpenAI({ model: "gpt-4o" });
      break;
    case "anthropic":
      model = new ChatAnthropic({ model: "claude-3-opus-20240229" });
      break;
    case "google":
      model = new ChatGoogleGenerativeAI({ model: "gemini-pro" });
      break;
    // Add more providers as needed
    default:
      throw new Error(`Unknown provider: ${providerName}`);
  }
}

// Create a chain that works with any model
const promptTemplate = ChatPromptTemplate.fromTemplate(
  "Summarize the following text in {word_count} words: {text}"
);

// This chain will work with any provider we choose
const chain = RunnableSequence.from([
  promptTemplate,
  // model will be set dynamically
  () => model
]);

// Usage
setModel("openai");
const result1 = await chain.invoke({
  word_count: "100",
  text: "Long article to summarize..."
});

// Switch models mid-application
setModel("anthropic");
const result2 = await chain.invoke({
  word_count: "100",
  text: "Different article to summarize..."
});
Best Practices

Separate Configuration: Keep your model provider configuration separate from your business logic
Environment Variables: Store API keys in environment variables
Fallbacks: Create fallback mechanisms to switch providers if one fails
Abstraction: Use the LangChain abstractions to make your code provider-agnostic where possible

By using LangChain.js, you can easily switch between different LLM providers or even use multiple providers in the same application, allowing you to leverage the strengths of each model for different tasks.RetryClaude does not have the ability to run the code it generates yet.REAlso read this: https://js.langchain.com/docs/contributing/integrations/Then search for community integrations (llm chat models) that are availableEditI'll look at the LangChain.js contribution guide for integrations and search for available community-built LLM and chat model integrations.View result from scrape_url from my_tool_suite (local){
  `url`: `https://js.langchain.com/docs/contributing/integrations/`
}Skip to main content Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. Join our team! Integrations API Reference More People Community Error reference External guides Contributing v0.3 v0.3 v0.2 v0.1 ü¶úüîó LangSmith LangSmith Docs LangChain Hub LangServe Python Docs Chat Search Contributing Welcome Contributors Repository Structure Contribute Code Testing Documentation Contribute Integrations FAQ Contributing Contribute Integrations On this page Contribute Integrations To begin, make sure you have all the dependencies outlined in guide on Contributing Code . There are a few different places you can contribute integrations for LangChain: Community : For lighter-weight integrations that are primarily maintained by LangChain and the Open Source Community. Partner Packages : For independent packages that are co-maintained by LangChain and a partner. For the most part, new integrations should be added to the Community package. Partner packages require more maintenance as separate packages, so please confirm with the LangChain team before creating a new partner package. In the following sections, we'll walk through how to contribute to each of these packages from a fake company, Parrot Link AI . Community package ‚Äã The @langchain/community package is in libs/langchain-community and contains most integrations. It can be installed with e.g. npm install @langchain/community , and exported members can be imported with code like import { ChatParrotLink } from "@langchain/community/chat_models/parrot_link" ; import { ParrotLinkLLM } from "@langchain/community/llms/parrot_link" ; import { ParrotLinkVectorStore } from "@langchain/community/vectorstores/parrot_link" ; The @langchain/community package relies on manually-installed dependent packages, so you will see errors if you try to import a package that is not installed. In our fake example, if you tried to import ParrotLinkLLM without installing parrot-link-sdk , you would see an error telling you that the package failed to import. Let's say we wanted to implement a chat model for Parrot Link AI. We would create a new file in libs/langchain-community/src/chat_models/parrot_link.ts with something like the following code: import { SimpleChatModel , } from "@langchain/core/language_models/chat_models" ; export class ChatParrotLink extends SimpleChatModel { ... Tests are colocated in the src/ directory, so you could write them in files like the below: Unit tests: libs/langchain-community/src/chat_models/tests/parrot_link.test.ts Integration tests: libs/langchain-community/src/chat_models/tests/parrot_link.int.test.ts Unit tests should not have any external API calls or require any environment variables. You should add documentation to: docs/core_docs/docs/integrations/chat/parrot_link.mdx Partner package in LangChain repo ‚Äã Partner packages can be hosted in the LangChain monorepo. Partner packages in the LangChain repo should be placed under libs/langchain-{partner} A package is installed by users with npm install @langchain/{partner} , and the package members can be imported with code like: import { X } from "@langchain/{partner}" ; Set up a new package ‚Äã To set up a new partner package, you can use create-langchain-integration , a utility that will automatically scaffold a repo with support for both ESM + CJS entrypoints. You can run it like this within the libs/ folder: cd libs/ npx create-langchain-integration Then, follow the prompts to name your package. The default package will include stubs for a Chat Model, an LLM, and/or a Vector Store. You should delete any of the files you won't use and remove them from index.ts . Dependencies ‚Äã If your package needs dependencies, such as your company's SDK, you can add them to your package's package.json file as normal: npm install parrot-link-sdk Write Unit and Integration Tests ‚Äã Some basic tests are presented in the src/tests/ directory. You should add more tests to cover your package's functionality. For information on running and implementing tests, see the Testing guide . Write documentation ‚Äã Please copy and use the appropriate template from here: https://github.com/langchain-ai/langchainjs/tree/main/libs/langchain-scripts/src/cli/docs/templates You should place the notebooks with examples in the relevant docs/core_docs/docs/integrations directory in the monorepo root. (If Necessary) Deprecate community integration ‚Äã Note: this is only necessary if you're migrating an existing community integration into a partner package. If the component you're integrating is net-new to LangChain (i.e. not already in the community package), you can skip this step. Let's pretend we migrated our ChatParrotLink chat model from the community package to the partner package. We would need to deprecate the old model in the community package. We can do this using a @deprecated TSDoc comment. Before our change, our chat model might look like this: class ChatParrotLink extends SimpleChatModel { ... After our change, it would look like this: /** @deprecated Install and import from `@langchain/parrot-link` instead. */ class ChatParrotLink extends SimpleChatModel { ... You should do this for each component that you're migrating to the partner package. Was this page helpful? You can also leave detailed feedback on GitHub . Previous Style guide Next FAQ Community package Partner package in LangChain repo Set up a new package Dependencies Write Unit and Integration Tests Write documentation (If Necessary) Deprecate community integration Community Twitter GitHub Python JS/TS More Homepage Blog Copyright ¬© 2025 LangChain, Inc. Skip to main content Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. Join our team! Integrations API Reference More People Community Error reference External guides Contributing v0.3 v0.3 v0.2 v0.1 ü¶úüîó LangSmith LangSmith Docs LangChain Hub LangServe Python Docs Chat Search Contributing Welcome Contributors Repository Structure Contribute Code Testing Documentation Contribute Integrations FAQ Contributing Contribute Integrations On this page Contribute Integrations To begin, make sure you have all the dependencies outlined in guide on Contributing Code . There are a few different places you can contribute integrations for LangChain: Community : For lighter-weight integrations that are primarily maintained by LangChain and the Open Source Community. Partner Packages : For independent packages that are co-maintained by LangChain and a partner. For the most part, new integrations should be added to the Community package. Partner packages require more maintenance as separate packages, so please confirm with the LangChain team before creating a new partner package. In the following sections, we'll walk through how to contribute to each of these packages from a fake company, Parrot Link AI . Community package ‚Äã The @langchain/community package is in libs/langchain-community and contains most integrations. It can be installed with e.g. npm install @langchain/community , and exported members can be imported with code like import { ChatParrotLink } from "@langchain/community/chat_models/parrot_link" ; import { ParrotLinkLLM } from "@langchain/community/llms/parrot_link" ; import { ParrotLinkVectorStore } from "@langchain/community/vectorstores/parrot_link" ; The @langchain/community package relies on manually-installed dependent packages, so you will see errors if you try to import a package that is not installed. In our fake example, if you tried to import ParrotLinkLLM without installing parrot-link-sdk , you would see an error telling you that the package failed to import. Let's say we wanted to implement a chat model for Parrot Link AI. We would create a new file in libs/langchain-community/src/chat_models/parrot_link.ts with something like the following code: import { SimpleChatModel , } from "@langchain/core/language_models/chat_models" ; export class ChatParrotLink extends SimpleChatModel { ... Tests are colocated in the src/ directory, so you could write them in files like the below: Unit tests: libs/langchain-community/src/chat_models/tests/parrot_link.test.ts Integration tests: libs/langchain-community/src/chat_models/tests/parrot_link.int.test.ts Unit tests should not have any external API calls or require any environment variables. You should add documentation to: docs/core_docs/docs/integrations/chat/parrot_link.mdx Partner package in LangChain repo ‚Äã Partner packages can be hosted in the LangChain monorepo. Partner packages in the LangChain repo should be placed under libs/langchain-{partner} A package is installed by users with npm install @langchain/{partner} , and the package members can be imported with code like: import { X } from "@langchain/{partner}" ; Set up a new package ‚Äã To set up a new partner package, you can use create-langchain-integration , a utility that will automatically scaffold a repo with support for both ESM + CJS entrypoints. You can run it like this within the libs/ folder: cd libs/ npx create-langchain-integration Then, follow the prompts to name your package. The default package will include stubs for a Chat Model, an LLM, and/or a Vector Store. You should delete any of the files you won't use and remove them from index.ts . Dependencies ‚Äã If your package needs dependencies, such as your company's SDK, you can add them to your package's package.json file as normal: npm install parrot-link-sdk Write Unit and Integration Tests ‚Äã Some basic tests are presented in the src/tests/ directory. You should add more tests to cover your package's functionality. For information on running and implementing tests, see the Testing guide . Write documentation ‚Äã Please copy and use the appropriate template from here: https://github.com/langchain-ai/langchainjs/tree/main/libs/langchain-scripts/src/cli/docs/templates You should place the notebooks with examples in the relevant docs/core_docs/docs/integrations directory in the monorepo root. (If Necessary) Deprecate community integration ‚Äã Note: this is only necessary if you're migrating an existing community integration into a partner package. If the component you're integrating is net-new to LangChain (i.e. not already in the community package), you can skip this step. Let's pretend we migrated our ChatParrotLink chat model from the community package to the partner package. We would need to deprecate the old model in the community package. We can do this using a @deprecated TSDoc comment. Before our change, our chat model might look like this: class ChatParrotLink extends SimpleChatModel { ... After our change, it would look like this: /** @deprecated Install and import from `@langchain/parrot-link` instead. */ class ChatParrotLink extends SimpleChatModel { ... You should do this for each component that you're migrating to the partner package. Was this page helpful? You can also leave detailed feedback on GitHub . Previous Style guide Next FAQ Community package Partner package in LangChain repo Set up a new package Dependencies Write Unit and Integration Tests Write documentation (If Necessary) Deprecate community integration Community Twitter GitHub Python JS/TS More Homepage Blog Copyright ¬© 2025 LangChain, Inc. Skip to main content Skip to main content Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. Join our team! Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. Join our team! Join our team! Contributing Welcome Contributors Repository Structure Contribute Code Testing Documentation Contribute Integrations FAQ Contributing Contribute Integrations On this page Contribute Integrations To begin, make sure you have all the dependencies outlined in guide on Contributing Code . There are a few different places you can contribute integrations for LangChain: Community : For lighter-weight integrations that are primarily maintained by LangChain and the Open Source Community. Partner Packages : For independent packages that are co-maintained by LangChain and a partner. For the most part, new integrations should be added to the Community package. Partner packages require more maintenance as separate packages, so please confirm with the LangChain team before creating a new partner package. In the following sections, we'll walk through how to contribute to each of these packages from a fake company, Parrot Link AI . Community package ‚Äã The @langchain/community package is in libs/langchain-community and contains most integrations. It can be installed with e.g. npm install @langchain/community , and exported members can be imported with code like import { ChatParrotLink } from "@langchain/community/chat_models/parrot_link" ; import { ParrotLinkLLM } from "@langchain/community/llms/parrot_link" ; import { ParrotLinkVectorStore } from "@langchain/community/vectorstores/parrot_link" ; The @langchain/community package relies on manually-installed dependent packages, so you will see errors if you try to import a package that is not installed. In our fake example, if you tried to import ParrotLinkLLM without installing parrot-link-sdk , you would see an error telling you that the package failed to import. Let's say we wanted to implement a chat model for Parrot Link AI. We would create a new file in libs/langchain-community/src/chat_models/parrot_link.ts with something like the following code: import { SimpleChatModel , } from "@langchain/core/language_models/chat_models" ; export class ChatParrotLink extends SimpleChatModel { ... Tests are colocated in the src/ directory, so you could write them in files like the below: Unit tests: libs/langchain-community/src/chat_models/tests/parrot_link.test.ts Integration tests: libs/langchain-community/src/chat_models/tests/parrot_link.int.test.ts Unit tests should not have any external API calls or require any environment variables. You should add documentation to: docs/core_docs/docs/integrations/chat/parrot_link.mdx Partner package in LangChain repo ‚Äã Partner packages can be hosted in the LangChain monorepo. Partner packages in the LangChain repo should be placed under libs/langchain-{partner} A package is installed by users with npm install @langchain/{partner} , and the package members can be imported with code like: import { X } from "@langchain/{partner}" ; Set up a new package ‚Äã To set up a new partner package, you can use create-langchain-integration , a utility that will automatically scaffold a repo with support for both ESM + CJS entrypoints. You can run it like this within the libs/ folder: cd libs/ npx create-langchain-integration Then, follow the prompts to name your package. The default package will include stubs for a Chat Model, an LLM, and/or a Vector Store. You should delete any of the files you won't use and remove them from index.ts . Dependencies ‚Äã If your package needs dependencies, such as your company's SDK, you can add them to your package's package.json file as normal: npm install parrot-link-sdk Write Unit and Integration Tests ‚Äã Some basic tests are presented in the src/tests/ directory. You should add more tests to cover your package's functionality. For information on running and implementing tests, see the Testing guide . Write documentation ‚Äã Please copy and use the appropriate template from here: https://github.com/langchain-ai/langchainjs/tree/main/libs/langchain-scripts/src/cli/docs/templates You should place the notebooks with examples in the relevant docs/core_docs/docs/integrations directory in the monorepo root. (If Necessary) Deprecate community integration ‚Äã Note: this is only necessary if you're migrating an existing community integration into a partner package. If the component you're integrating is net-new to LangChain (i.e. not already in the community package), you can skip this step. Let's pretend we migrated our ChatParrotLink chat model from the community package to the partner package. We would need to deprecate the old model in the community package. We can do this using a @deprecated TSDoc comment. Before our change, our chat model might look like this: class ChatParrotLink extends SimpleChatModel { ... After our change, it would look like this: /** @deprecated Install and import from `@langchain/parrot-link` instead. */ class ChatParrotLink extends SimpleChatModel { ... You should do this for each component that you're migrating to the partner package. Was this page helpful? You can also leave detailed feedback on GitHub . Previous Style guide Next FAQ Community package Partner package in LangChain repo Set up a new package Dependencies Write Unit and Integration Tests Write documentation (If Necessary) Deprecate community integration Contributing Welcome Contributors Repository Structure Contribute Code Testing Documentation Contribute Integrations FAQ Contributing Contribute Integrations On this page Contribute Integrations To begin, make sure you have all the dependencies outlined in guide on Contributing Code . There are a few different places you can contribute integrations for LangChain: Community : For lighter-weight integrations that are primarily maintained by LangChain and the Open Source Community. Partner Packages : For independent packages that are co-maintained by LangChain and a partner. For the most part, new integrations should be added to the Community package. Partner packages require more maintenance as separate packages, so please confirm with the LangChain team before creating a new partner package. In the following sections, we'll walk through how to contribute to each of these packages from a fake company, Parrot Link AI . Community package ‚Äã The @langchain/community package is in libs/langchain-community and contains most integrations. It can be installed with e.g. npm install @langchain/community , and exported members can be imported with code like import { ChatParrotLink } from "@langchain/community/chat_models/parrot_link" ; import { ParrotLinkLLM } from "@langchain/community/llms/parrot_link" ; import { ParrotLinkVectorStore } from "@langchain/community/vectorstores/parrot_link" ; The @langchain/community package relies on manually-installed dependent packages, so you will see errors if you try to import a package that is not installed. In our fake example, if you tried to import ParrotLinkLLM without installing parrot-link-sdk , you would see an error telling you that the package failed to import. Let's say we wanted to implement a chat model for Parrot Link AI. We would create a new file in libs/langchain-community/src/chat_models/parrot_link.ts with something like the following code: import { SimpleChatModel , } from "@langchain/core/language_models/chat_models" ; export class ChatParrotLink extends SimpleChatModel { ... Tests are colocated in the src/ directory, so you could write them in files like the below: Unit tests: libs/langchain-community/src/chat_models/tests/parrot_link.test.ts Integration tests: libs/langchain-community/src/chat_models/tests/parrot_link.int.test.ts Unit tests should not have any external API calls or require any environment variables. You should add documentation to: docs/core_docs/docs/integrations/chat/parrot_link.mdx Partner package in LangChain repo ‚Äã Partner packages can be hosted in the LangChain monorepo. Partner packages in the LangChain repo should be placed under libs/langchain-{partner} A package is installed by users with npm install @langchain/{partner} , and the package members can be imported with code like: import { X } from "@langchain/{partner}" ; Set up a new package ‚Äã To set up a new partner package, you can use create-langchain-integration , a utility that will automatically scaffold a repo with support for both ESM + CJS entrypoints. You can run it like this within the libs/ folder: cd libs/ npx create-langchain-integration Then, follow the prompts to name your package. The default package will include stubs for a Chat Model, an LLM, and/or a Vector Store. You should delete any of the files you won't use and remove them from index.ts . Dependencies ‚Äã If your package needs dependencies, such as your company's SDK, you can add them to your package's package.json file as normal: npm install parrot-link-sdk Write Unit and Integration Tests ‚Äã Some basic tests are presented in the src/tests/ directory. You should add more tests to cover your package's functionality. For information on running and implementing tests, see the Testing guide . Write documentation ‚Äã Please copy and use the appropriate template from here: https://github.com/langchain-ai/langchainjs/tree/main/libs/langchain-scripts/src/cli/docs/templates You should place the notebooks with examples in the relevant docs/core_docs/docs/integrations directory in the monorepo root. (If Necessary) Deprecate community integration ‚Äã Note: this is only necessary if you're migrating an existing community integration into a partner package. If the component you're integrating is net-new to LangChain (i.e. not already in the community package), you can skip this step. Let's pretend we migrated our ChatParrotLink chat model from the community package to the partner package. We would need to deprecate the old model in the community package. We can do this using a @deprecated TSDoc comment. Before our change, our chat model might look like this: class ChatParrotLink extends SimpleChatModel { ... After our change, it would look like this: /** @deprecated Install and import from `@langchain/parrot-link` instead. */ class ChatParrotLink extends SimpleChatModel { ... You should do this for each component that you're migrating to the partner package. Was this page helpful? You can also leave detailed feedback on GitHub . Previous Style guide Next FAQ Community package Partner package in LangChain repo Set up a new package Dependencies Write Unit and Integration Tests Write documentation (If Necessary) Deprecate community integration Contributing Contribute Integrations On this page Contribute Integrations To begin, make sure you have all the dependencies outlined in guide on Contributing Code . There are a few different places you can contribute integrations for LangChain: Community : For lighter-weight integrations that are primarily maintained by LangChain and the Open Source Community. Partner Packages : For independent packages that are co-maintained by LangChain and a partner. For the most part, new integrations should be added to the Community package. Partner packages require more maintenance as separate packages, so please confirm with the LangChain team before creating a new partner package. In the following sections, we'll walk through how to contribute to each of these packages from a fake company, Parrot Link AI . Community package ‚Äã The @langchain/community package is in libs/langchain-community and contains most integrations. It can be installed with e.g. npm install @langchain/community , and exported members can be imported with code like import { ChatParrotLink } from "@langchain/community/chat_models/parrot_link" ; import { ParrotLinkLLM } from "@langchain/community/llms/parrot_link" ; import { ParrotLinkVectorStore } from "@langchain/community/vectorstores/parrot_link" ; The @langchain/community package relies on manually-installed dependent packages, so you will see errors if you try to import a package that is not installed. In our fake example, if you tried to import ParrotLinkLLM without installing parrot-link-sdk , you would see an error telling you that the package failed to import. Let's say we wanted to implement a chat model for Parrot Link AI. We would create a new file in libs/langchain-community/src/chat_models/parrot_link.ts with something like the following code: import { SimpleChatModel , } from "@langchain/core/language_models/chat_models" ; export class ChatParrotLink extends SimpleChatModel { ... Tests are colocated in the src/ directory, so you could write them in files like the below: Unit tests: libs/langchain-community/src/chat_models/tests/parrot_link.test.ts Integration tests: libs/langchain-community/src/chat_models/tests/parrot_link.int.test.ts Unit tests should not have any external API calls or require any environment variables. You should add documentation to: docs/core_docs/docs/integrations/chat/parrot_link.mdx Partner package in LangChain repo ‚Äã Partner packages can be hosted in the LangChain monorepo. Partner packages in the LangChain repo should be placed under libs/langchain-{partner} A package is installed by users with npm install @langchain/{partner} , and the package members can be imported with code like: import { X } from "@langchain/{partner}" ; Set up a new package ‚Äã To set up a new partner package, you can use create-langchain-integration , a utility that will automatically scaffold a repo with support for both ESM + CJS entrypoints. You can run it like this within the libs/ folder: cd libs/ npx cr

... (content truncated)View result from brave_search from my_tool_suite (local){
  `count`: 10,
  `query`: `langchain.js community llm chat models list integration`
}Title: Chat models | ü¶úÔ∏èüîó Langchain
URL: https://js.langchain.com/docs/integrations/chat/
Description: <strong>Chat</strong> <strong>models</strong> are language <strong>models</strong> that use a sequence of messages as inputs and return messages as outputs (as opposed to using plain text). These are generally newer <strong>models</strong>.

---

Title: Build a simple LLM application with chat models and prompt templates | ü¶úÔ∏èüîó Langchain
URL: https://js.langchain.com/docs/tutorials/llm_chain/
Description: In this quickstart we‚Äôll show you how to build a simple <strong>LLM</strong> application

---

Title: LLMs | ü¶úÔ∏èüîó Langchain
URL: https://js.langchain.com/docs/integrations/llms/
Description: You are currently on a page documenting the use of text completion <strong>models</strong>. Many of the latest and most popular <strong>models</strong> <strong>are</strong> <strong>chat</strong> completion <strong>models</strong>.

---

Title: WebLLM | ü¶úÔ∏èüîó Langchain
URL: https://js.langchain.com/docs/integrations/chat/web_llm/
Description: Help us build the <strong>JS</strong> tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. Join our team! ... Only available in web environments. You can run LLMs directly in your web browser using <strong>LangChain</strong>&#x27;s WebLLM <strong>integration</strong>. You&#x27;ll need to install the WebLLM SDK module to communicate with your local <strong>model</strong>...

---

Title: LangChain
URL: https://www.langchain.com/
Description: <strong>LangChain</strong>‚Äôs suite of products supports developers along each step of their development journey.

---

Title: How to use chat models to call tools | ü¶úÔ∏èüîó Langchain
URL: https://js.langchain.com/docs/how_to/tool_calling/
Description: Subsequent invocations of the <strong>chat</strong> <strong>model</strong> will include tool schemas in its calls to the <strong>LLM</strong>. ... As of @<strong>langchain</strong>/core version 0.2.9, all <strong>chat</strong> <strong>models</strong> with tool calling capabilities now support OpenAI-formatted tools. ... See this section for general instructions on installing <strong>integration</strong> packages.

---

Title: How to create a custom chat model class | ü¶úÔ∏èüîó LangChain
URL: https://python.langchain.com/docs/how_to/custom_chat_model/
Description: This guide assumes familiarity with the following concepts:

---

Title: Build a simple LLM application with chat models and prompt templates | ü¶úÔ∏èüîó LangChain
URL: https://python.langchain.com/docs/tutorials/llm_chain/
Description: In this quickstart we&#x27;ll show you how to build a simple <strong>LLM</strong> application with <strong>LangChain</strong>. This application will translate text from English into another language. This is a relatively simple <strong>LLM</strong> application - it&#x27;s just a single <strong>LLM</strong> call plus some prompting. Still, this is a great way to get started ...

---

Title: How to stream chat model responses | ü¶úÔ∏èüîó Langchain
URL: https://js.langchain.com/docs/how_to/chat_streaming/
Description: All <strong>chat</strong> <strong>models</strong> implement the Runnable interface, which comes with default implementations of standard runnable methods (i.e. invoke, batch, stream, streamEvents). This guide covers how to use these methods to stream output from <strong>chat</strong> <strong>models</strong> ¬∑ The default implementation does not provide support ...

---

Title: LangChain on Databricks for LLM development | Databricks Documentation
URL: https://docs.databricks.com/en/large-language-models/langchain.html
Description: Learn about the <strong>LangChain</strong> <strong>integrations</strong> that facilitate the development and deployment of large language <strong>models</strong> (LLMs) on Databricks.
View result from brave_search from my_tool_suite (local){
  `count`: 5,
  `query`: `langchain.js @langchain/community chat models list github`
}Title: Chat models | ü¶úÔ∏èüîó Langchain
URL: https://js.langchain.com/docs/integrations/chat/
Description: <strong>import { ChatMistralAI } from &quot;@langchain/mistralai&quot;; const model = new ChatMistralAI({ model: &quot;mistral-large-latest&quot;, temperature: 0 });</strong> ... See this section for general instructions on installing integration packages. ... import { ChatVertexAI } from &quot;@langchain/google-vertexai&quot;; const model ...

---

Title: GitHub - langchain-ai/langchain: ü¶úüîó Build context-aware reasoning applications
URL: https://github.com/langchain-ai/langchain
Description: ü¶úüîó Build context-aware reasoning applications. Contribute to <strong>langchain</strong>-ai/<strong>langchain</strong> development by creating an account on <strong>GitHub</strong>.

---

Title: LangChain
URL: https://www.langchain.com/
Description: <strong>LangChain</strong>‚Äôs suite of products supports developers along each step of their development journey.

---

Title: GitHub - langchain-ai/langchainjs: ü¶úüîó Build context-aware reasoning applications ü¶úüîó
URL: https://github.com/langchain-ai/langchainjs
Description: ü¶úüîó Build context-aware reasoning applications ü¶úüîó. Contribute to <strong>langchain</strong>-ai/langchainjs development by creating an account on <strong>GitHub</strong>.

---

Title: langchain-community: 0.3.21 ‚Äî ü¶úüîó LangChain documentation
URL: https://python.langchain.com/api_reference/community/
Description: Skip to main content ¬∑ Back to top ¬∑ <strong>GitHub</strong> ¬∑ X / Twitter
View result from scrape_url from my_tool_suite (local){
  `url`: `https://github.com/langchain-ai/langchainjs/tree/main/libs/langchain-community/src/chat_models`
}Skip to content Navigation Menu Toggle navigation Sign in Product GitHub Copilot Write better code with AI GitHub Advanced Security Find and fix vulnerabilities Actions Automate any workflow Codespaces Instant dev environments Issues Plan and track work Code Review Manage code changes Discussions Collaborate outside of code Code Search Find more, search less Explore All features Documentation GitHub Skills Blog Solutions By company size Enterprises Small and medium teams Startups Nonprofits By use case DevSecOps DevOps CI/CD View all use cases By industry Healthcare Financial services Manufacturing Government View all industries View all solutions Resources Topics AI DevOps Security Software Development View all Explore Learning Pathways Events & Webinars Ebooks & Whitepapers Customer Stories Partners Executive Insights Open Source GitHub Sponsors Fund open source developers The ReadME Project GitHub community articles Repositories Topics Trending Collections Enterprise Enterprise platform AI-powered developer platform Available add-ons GitHub Advanced Security Enterprise-grade security features Copilot for business Enterprise-grade AI features Premium Support Enterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation . Cancel Create saved search Sign in Sign up Reseting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert langchain-ai / langchainjs Public Notifications You must be signed in to change notification settings Fork 2.4k Star 14.2k Code Issues 76 Pull requests 98 Discussions Actions Projects 1 Security Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Security Insights Files main .devcontainer .github .vscode .yarn cookbook dependency_range_tests docs environment_tests examples langchain-core langchain libs create-langchain-integration langchain-anthropic langchain-aws langchain-azure-cosmosdb langchain-azure-dynamic-sessions langchain-azure-openai langchain-baidu-qianfan langchain-cerebras langchain-cloudflare langchain-cohere langchain-community scripts src agents caches callbacks chains chat_models bedrock iflytek_xinghuo tencent_hunyuan tests alibaba_tongyi.ts arcjet.ts baiduwenxin.ts cloudflare_workersai.ts deepinfra.ts fireworks.ts friendli.ts ibm.ts llama_cpp.ts minimax.ts moonshot.ts novita.ts ollama.ts perplexity.ts portkey.ts premai.ts togetherai.ts webllm.ts yandex.ts zhipuai.ts document_compressors document_loaders document_transformers embeddings experimental graphs indexes llms load memory retrievers storage stores structured_query tools types utils vectorstores index.ts .env.example .eslintrc.cjs .gitignore .prettierignore .prettierrc .release-it.json LICENSE README.md jest.config.cjs jest.env.cjs langchain.config.js package.json tsconfig.cjs.json tsconfig.json turbo.json langchain-deepseek langchain-exa langchain-google-cloud-sql-pg langchain-google-common langchain-google-gauth langchain-google-genai langchain-google-vertexai-web langchain-google-vertexai langchain-google-webauth langchain-groq langchain-mistralai langchain-mixedbread-ai langchain-mongodb langchain-nomic langchain-ollama langchain-openai langchain-pinecone langchain-qdrant langchain-redis langchain-scripts langchain-standard-tests langchain-textsplitters langchain-weaviate langchain-xai langchain-yandex .codecov.yml .editorconfig .gitattributes .gitignore .nvmrc .prettierignore .prettierrc .vercelignore .watchmanconfig .yarnrc.yml CONTRIBUTING.md LICENSE README.md SECURITY.md deno.json package.json release_workspace.js test-int-deps-docker-compose.yml tsconfig.json turbo.json yarn.lock Breadcrumbs langchainjs / libs / langchain-community / src / chat_models / Copy path Directory actions More options Directory actions More options Latest commit History History Breadcrumbs langchainjs / libs / langchain-community / src / chat_models / Top Folders and files Name Name Last commit message Last commit date parent directory .. bedrock bedrock iflytek_xinghuo iflytek_xinghuo tencent_hunyuan tencent_hunyuan tests tests alibaba_tongyi.ts alibaba_tongyi.ts arcjet.ts arcjet.ts baiduwenxin.ts baiduwenxin.ts cloudflare_workersai.ts cloudflare_workersai.ts deepinfra.ts deepinfra.ts fireworks.ts fireworks.ts friendli.ts friendli.ts ibm.ts ibm.ts llama_cpp.ts llama_cpp.ts minimax.ts minimax.ts moonshot.ts moonshot.ts novita.ts novita.ts ollama.ts ollama.ts perplexity.ts perplexity.ts portkey.ts portkey.ts premai.ts premai.ts togetherai.ts togetherai.ts webllm.ts webllm.ts yandex.ts yandex.ts zhipuai.ts zhipuai.ts View all files Footer ¬© 2025 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact Manage cookies Do not share my personal information You can‚Äôt perform that action at this time. Skip to content Navigation Menu Toggle navigation Sign in Product GitHub Copilot Write better code with AI GitHub Advanced Security Find and fix vulnerabilities Actions Automate any workflow Codespaces Instant dev environments Issues Plan and track work Code Review Manage code changes Discussions Collaborate outside of code Code Search Find more, search less Explore All features Documentation GitHub Skills Blog Solutions By company size Enterprises Small and medium teams Startups Nonprofits By use case DevSecOps DevOps CI/CD View all use cases By industry Healthcare Financial services Manufacturing Government View all industries View all solutions Resources Topics AI DevOps Security Software Development View all Explore Learning Pathways Events & Webinars Ebooks & Whitepapers Customer Stories Partners Executive Insights Open Source GitHub Sponsors Fund open source developers The ReadME Project GitHub community articles Repositories Topics Trending Collections Enterprise Enterprise platform AI-powered developer platform Available add-ons GitHub Advanced Security Enterprise-grade security features Copilot for business Enterprise-grade AI features Premium Support Enterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation . Cancel Create saved search Sign in Sign up Reseting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert langchain-ai / langchainjs Public Notifications You must be signed in to change notification settings Fork 2.4k Star 14.2k Code Issues 76 Pull requests 98 Discussions Actions Projects 1 Security Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Security Insights Files main .devcontainer .github .vscode .yarn cookbook dependency_range_tests docs environment_tests examples langchain-core langchain libs create-langchain-integration langchain-anthropic langchain-aws langchain-azure-cosmosdb langchain-azure-dynamic-sessions langchain-azure-openai langchain-baidu-qianfan langchain-cerebras langchain-cloudflare langchain-cohere langchain-community scripts src agents caches callbacks chains chat_models bedrock iflytek_xinghuo tencent_hunyuan tests alibaba_tongyi.ts arcjet.ts baiduwenxin.ts cloudflare_workersai.ts deepinfra.ts fireworks.ts friendli.ts ibm.ts llama_cpp.ts minimax.ts moonshot.ts novita.ts ollama.ts perplexity.ts portkey.ts premai.ts togetherai.ts webllm.ts yandex.ts zhipuai.ts document_compressors document_loaders document_transformers embeddings experimental graphs indexes llms load memory retrievers storage stores structured_query tools types utils vectorstores index.ts .env.example .eslintrc.cjs .gitignore .prettierignore .prettierrc .release-it.json LICENSE README.md jest.config.cjs jest.env.cjs langchain.config.js package.json tsconfig.cjs.json tsconfig.json turbo.json langchain-deepseek langchain-exa langchain-google-cloud-sql-pg langchain-google-common langchain-google-gauth langchain-google-genai langchain-google-vertexai-web langchain-google-vertexai langchain-google-webauth langchain-groq langchain-mistralai langchain-mixedbread-ai langchain-mongodb langchain-nomic langchain-ollama langchain-openai langchain-pinecone langchain-qdrant langchain-redis langchain-scripts langchain-standard-tests langchain-textsplitters langchain-weaviate langchain-xai langchain-yandex .codecov.yml .editorconfig .gitattributes .gitignore .nvmrc .prettierignore .prettierrc .vercelignore .watchmanconfig .yarnrc.yml CONTRIBUTING.md LICENSE README.md SECURITY.md deno.json package.json release_workspace.js test-int-deps-docker-compose.yml tsconfig.json turbo.json yarn.lock Breadcrumbs langchainjs / libs / langchain-community / src / chat_models / Copy path Directory actions More options Directory actions More options Latest commit History History Breadcrumbs langchainjs / libs / langchain-community / src / chat_models / Top Folders and files Name Name Last commit message Last commit date parent directory .. bedrock bedrock iflytek_xinghuo iflytek_xinghuo tencent_hunyuan tencent_hunyuan tests tests alibaba_tongyi.ts alibaba_tongyi.ts arcjet.ts arcjet.ts baiduwenxin.ts baiduwenxin.ts cloudflare_workersai.ts cloudflare_workersai.ts deepinfra.ts deepinfra.ts fireworks.ts fireworks.ts friendli.ts friendli.ts ibm.ts ibm.ts llama_cpp.ts llama_cpp.ts minimax.ts minimax.ts moonshot.ts moonshot.ts novita.ts novita.ts ollama.ts ollama.ts perplexity.ts perplexity.ts portkey.ts portkey.ts premai.ts premai.ts togetherai.ts togetherai.ts webllm.ts webllm.ts yandex.ts yandex.ts zhipuai.ts zhipuai.ts View all files Footer ¬© 2025 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact Manage cookies Do not share my personal information You can‚Äôt perform that action at this time. Skip to content Navigation Menu Toggle navigation Sign in Product GitHub Copilot Write better code with AI GitHub Advanced Security Find and fix vulnerabilities Actions Automate any workflow Codespaces Instant dev environments Issues Plan and track work Code Review Manage code changes Discussions Collaborate outside of code Code Search Find more, search less Explore All features Documentation GitHub Skills Blog Solutions By company size Enterprises Small and medium teams Startups Nonprofits By use case DevSecOps DevOps CI/CD View all use cases By industry Healthcare Financial services Manufacturing Government View all industries View all solutions Resources Topics AI DevOps Security Software Development View all Explore Learning Pathways Events & Webinars Ebooks & Whitepapers Customer Stories Partners Executive Insights Open Source GitHub Sponsors Fund open source developers The ReadME Project GitHub community articles Repositories Topics Trending Collections Enterprise Enterprise platform AI-powered developer platform Available add-ons GitHub Advanced Security Enterprise-grade security features Copilot for business Enterprise-grade AI features Premium Support Enterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation . Cancel Create saved search Sign in Sign up Reseting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert Skip to content You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert You signed in with another tab or window. Reload to refresh your session. Reload You signed out in another tab or window. Reload to refresh your session. Reload You switched accounts on another tab or window. Reload to refresh your session. Reload langchain-ai / langchainjs Public Notifications You must be signed in to change notification settings Fork 2.4k Star 14.2k Code Issues 76 Pull requests 98 Discussions Actions Projects 1 Security Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Security Insights Files main .devcontainer .github .vscode .yarn cookbook dependency_range_tests docs environment_tests examples langchain-core langchain libs create-langchain-integration langchain-anthropic langchain-aws langchain-azure-cosmosdb langchain-azure-dynamic-sessions langchain-azure-openai langchain-baidu-qianfan langchain-cerebras langchain-cloudflare langchain-cohere langchain-community scripts src agents caches callbacks chains chat_models bedrock iflytek_xinghuo tencent_hunyuan tests alibaba_tongyi.ts arcjet.ts baiduwenxin.ts cloudflare_workersai.ts deepinfra.ts fireworks.ts friendli.ts ibm.ts llama_cpp.ts minimax.ts moonshot.ts novita.ts ollama.ts perplexity.ts portkey.ts premai.ts togetherai.ts webllm.ts yandex.ts zhipuai.ts document_compressors document_loaders document_transformers embeddings experimental graphs indexes llms load memory retrievers storage stores structured_query tools types utils vectorstores index.ts .env.example .eslintrc.cjs .gitignore .prettierignore .prettierrc .release-it.json LICENSE README.md jest.config.cjs jest.env.cjs langchain.config.js package.json tsconfig.cjs.json tsconfig.json turbo.json langchain-deepseek langchain-exa langchain-google-cloud-sql-pg langchain-google-common langchain-google-gauth langchain-google-genai langchain-google-vertexai-web langchain-google-vertexai langchain-google-webauth langchain-groq langchain-mistralai langchain-mixedbread-ai langchain-mongodb langchain-nomic langchain-ollama langchain-openai langchain-pinecone langchain-qdrant langchain-redis langchain-scripts langchain-standard-tests langchain-textsplitters langchain-weaviate langchain-xai langchain-yandex .codecov.yml .editorconfig .gitattributes .gitignore .nvmrc .prettierignore .prettierrc .vercelignore .watchmanconfig .yarnrc.yml CONTRIBUTING.md LICENSE README.md SECURITY.md deno.json package.json release_workspace.js test-int-deps-docker-compose.yml tsconfig.json turbo.json yarn.lock Breadcrumbs langchainjs / libs / langchain-community / src / chat_models / Copy path Directory actions More options Directory actions More options Latest commit History History Breadcrumbs langchainjs / libs / langchain-community / src / chat_models / Top Folders and files Name Name Last commit message Last commit date parent directory .. bedrock bedrock iflytek_xinghuo iflytek_xinghuo tencent_hunyuan tencent_hunyuan tests tests alibaba_tongyi.ts alibaba_tongyi.ts arcjet.ts arcjet.ts baiduwenxin.ts baiduwenxin.ts cloudflare_workersai.ts cloudflare_workersai.ts deepinfra.ts deepinfra.ts fireworks.ts fireworks.ts friendli.ts friendli.ts ibm.ts ibm.ts llama_cpp.ts llama_cpp.ts minimax.ts minimax.ts moonshot.ts moonshot.ts novita.ts novita.ts ollama.ts ollama.ts perplexity.ts perplexity.ts portkey.ts portkey.ts premai.ts premai.ts togetherai.ts togetherai.ts webllm.ts webllm.ts yandex.ts yandex.ts zhipuai.ts zhipuai.ts View all files langchain-ai / langchainjs Public Notifications You must be signed in to change notification settings Fork 2.4k Star 14.2k Code Issues 76 Pull requests 98 Discussions Actions Projects 1 Security Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Security Insights Files main .devcontainer .github .vscode .yarn cookbook dependency_range_tests docs environment_tests examples langchain-core langchain libs create-langchain-integration langchain-anthropic langchain-aws langchain-azure-cosmosdb langchain-azure-dynamic-sessions langchain-azure-openai langchain-baidu-qianfan langchain-cerebras langchain-cloudflare langchain-cohere langchain-community scripts src agents caches callbacks chains chat_models bedrock iflytek_xinghuo tencent_hunyuan tests alibaba_tongyi.ts arcjet.ts baiduwenxin.ts cloudflare_workersai.ts deepinfra.ts fireworks.ts friendli.ts ibm.ts llama_cpp.ts minimax.ts moonshot.ts novita.ts ollama.ts perplexity.ts portkey.ts premai.ts togetherai.ts webllm.ts yandex.ts zhipuai.ts document_compressors document_loaders document_transformers embeddings experimental graphs indexes llms load memory retrievers storage stores structured_query tools types utils vectorstores index.ts .env.example .eslintrc.cjs .gitignore .prettierignore .prettierrc .release-it.json LICENSE README.md jest.config.cjs jest.env.cjs langchain.config.js package.json tsconfig.cjs.json tsconfig.json turbo.json langchain-deepseek langchain-exa langchain-google-cloud-sql-pg langchain-google-common langchain-google-gauth langchain-google-genai langchain-google-vertexai-web langchain-google-vertexai langchain-google-webauth langchain-groq langchain-mistralai langchain-mixedbread-ai langchain-mongodb langchain-nomic langchain-ollama langchain-openai langchain-pinecone langchain-qdrant langchain-redis langchain-scripts langchain-standard-tests langchain-textsplitters langchain-weaviate langchain-xai langchain-yandex .codecov.yml .editorconfig .gitattributes .gitignore .nvmrc .prettierignore .prettierrc .vercelignore .watchmanconfig .yarnrc.yml CONTRIBUTING.md LICENSE README.md SECURITY.md deno.json package.json release_workspace.js test-int-deps-docker-compose.yml tsconfig.json turbo.json yarn.lock Breadcrumbs langchainjs / libs / langchain-community / src / chat_models / Copy path Directory actions More options Directory actions More options Latest commit History History Breadcrumbs langchainjs / libs / langchain-community / src / chat_models / Top Folders and files Name Name Last commit message Last commit date parent directory .. bedrock bedrock iflytek_xinghuo iflytek_xinghuo tencent_hunyuan tencent_hunyuan tests tests alibaba_tongyi.ts alibaba_tongyi.ts arcjet.ts arcjet.ts baiduwenxin.ts baiduwenxin.ts cloudflare_workersai.ts cloudflare_workersai.ts deepinfra.ts deepinfra.ts fireworks.ts fireworks.ts friendli.ts friendli.ts ibm.ts ibm.ts llama_cpp.ts llama_cpp.ts minimax.ts minimax.ts moonshot.ts moonshot.ts novita.ts novita.ts ollama.ts ollama.ts perplexity.ts perplexity.ts portkey.ts portkey.ts premai.ts premai.ts togetherai.ts togetherai.ts webllm.ts webllm.ts yandex.ts yandex.ts zhipuai.ts zhipuai.ts View all files langchain-ai / langchainjs Public Notifications You must be signed in to change notification settings Fork 2.4k Star 14.2k Code Issues 76 Pull requests 98 Discussions Actions Projects 1 Security Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Security Insights Files main .devcontainer .github .vscode .yarn cookbook dependency_range_tests docs environment_tests examples langchain-core langchain libs create-langchain-integration langchain-anthropic langchain-aws langchain-azure-cosmosdb langchain-azure-dynamic-sessions langchain-azure-openai langchain-baidu-qianfan langchain-cerebras langchain-cloudflare langchain-cohere langchain-community scripts src agents caches callbacks chains chat_models bedrock iflytek_xinghuo tencent_hunyuan tests alibaba_tongyi.ts arcjet.ts baiduwenxin.ts cloudflare_workersai.ts deepinfra.ts fireworks.ts friendli.ts ibm.ts llama_cpp.ts minimax.ts moonshot.ts novita.ts ollama.ts perplexity.ts portkey.ts premai.ts togetherai.ts webllm.ts yandex.ts zhipuai.ts document_compressors document_loaders document_transformers embeddings experimental graphs indexes llms load memory retrievers storage stores structured_query tools types utils vectorstores index.ts .env.example .eslintrc.cjs .gitignore .prettierignore .prettierrc .release-it.json LICENSE README.md jest.config.cjs jest.env.cjs langchain.config.js package.json tsconfig.cjs.json tsconfig.json turbo.json langchain-deepseek langchain-exa langchain-google-cloud-sql-pg langchain-google-common langchain-google-gauth langchain-google-genai langchain-google-vertexai-web langchain-google-vertexai langchain-google-webauth langchain-groq langchain-mistralai langchain-mixedbread-ai langchain-mongodb langchain-nomic langchain-ollama langchain-openai langchain-pinecone langchain-qdrant langchain-redis langchain-scripts langchain-standard-tests langchain-textsplitters langchain-weaviate langchain-xai langchain-yandex .codecov.yml .editorconfig .gitattributes .gitignore .nvmrc .prettierignore .prettierrc .vercelignore .watchmanconfig .yarnrc.yml CONTRIBUTING.md LICENSE README.md SECURITY.md deno.json package.json release_workspace.js test-int-deps-docker-compose.yml tsconfig.json turbo.json yarn.lock Breadcrumbs langchainjs / libs / langchain-community / src / chat_models / Copy path Directory actions More options Directory actions More options Latest commit History History Breadcrumbs langchainjs / libs / langchain-community / src / chat_models / Top Folders and files Name Name Last commit message Last commit date parent directory .. bedrock bedrock iflytek_xinghuo iflytek_xinghuo tencent_hunyuan tencent_hunyuan tests tests alibaba_tongyi.ts alibaba_tongyi.ts arcjet.ts arcjet.ts baiduwenxin.ts baiduwenxin.ts cloudflare_workersai.ts cloudflare_workersai.ts deepinfra.ts deepinfra.ts fireworks.ts fireworks.ts friendli.ts friendli.ts ibm.ts ibm.ts llama_cpp.ts llama_cpp.ts minimax.ts minimax.ts moonshot.ts moonshot.ts novita.ts novita.ts ollama.ts ollama.ts perplexity.ts perplexity.ts portkey.ts portkey.ts premai.ts premai.ts togetherai.ts togetherai.ts webllm.ts webllm.ts yandex.ts yandex.ts zhipuai.ts zhipuai.ts View all files langchain-ai / langchainjs Public Notifications You must be signed in to change notification settings Fork 2.4k Star 14.2k Code Issues 76 Pull requests 98 Discussions Actions Projects 1 Security Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Security Insights langchain-ai / langchainjs Public Notifications You must be signed in to change notification settings Fork 2.4k Star 14.2k langchain-ai / langchainjs Public langchain-ai / langchainjs Public langchain-ai langchain-ai / langchainjs Public Notifications You must be signed in to change notification settings Fork 2.4k Star 14.2k Notifications You must be signed in to change notification settings Notifications Fork 2.4k Fork 2.4k 2.4k Star 14.2k Star 14.2k Star 14.2k Star 14.2k Files main .devcontainer .github .vscode .yarn cookbook dependency_range_tests docs environment_tests examples langchain-core langchain libs create-langchain-integration langchain-anthropic langchain-aws langchain-azure-cosmosdb langchain-azure-dynamic-sessions langchain-azure-openai langchain-baidu-qianfan langchain-cerebras langchain-cloudflare langchain-cohere langchain-community scripts src agents caches callbacks chains chat_models bedrock iflytek_xinghuo tencent_hunyuan tests alibaba_tongyi.ts arcjet.ts baiduwenxin.ts cloudflare_workersai.ts deepinfra.ts fireworks.ts friendli.ts ibm.ts llama_cpp.ts minimax.ts moonshot.ts novita.ts ollama.ts perplexity.ts portkey.ts premai.ts togetherai.ts webllm.ts yandex.ts zhipuai.ts document_compressors document_loaders document_transformers embeddings experimental graphs indexes llms load memory retrievers storage stores structured_query tools types utils vectorstores index.ts .env.example .eslintrc.cjs .gitignore .prettierignore .prettierrc .release-it.json LICENSE README.md jest.config.cjs jest.env.cjs langchain.config.js package.json tsconfig.cjs.json tsconfig.json turbo.json langchain-deepseek langchain-exa langchain-google-cloud-sql-pg langchain-google-common langchain-google-gauth langchain-google-genai langchain-google-vertexai-web langchain-google-vertexai langchain-google-webauth langchain-groq langchain-mistralai langchain-mixedbread-ai langchain-mongodb langchain-nomic langchain-ollama langchain-openai langchain-pinecone langchain-qdrant langchain-redis langchain-scripts langchain-standard-tests langchain-textsplitters langchain-weaviate langchain-xa

... (content truncated)View result from scrape_url from my_tool_suite (local){
  `url`: `https://js.langchain.com/docs/integrations/chat/`
}Skip to main content Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. Join our team! Integrations API Reference More People Community Error reference External guides Contributing v0.3 v0.3 v0.2 v0.1 ü¶úüîó LangSmith LangSmith Docs LangChain Hub LangServe Python Docs Chat Search Providers Providers Anthropic AWS Google Microsoft OpenAI Components Chat models Chat models Alibaba Tongyi Anthropic Arcjet Redact Azure OpenAI Baidu Qianfan Baidu Wenxin Amazon Bedrock Amazon Bedrock Converse Cerebras Cloudflare Workers AI Cohere Deep Infra DeepSeek DeepSeek Fake LLM Fireworks Friendli Google GenAI Google Vertex AI Groq IBM watsonx.ai Llama CPP Minimax MistralAI Moonshot NIBittensorChatModel Novita AI Ollama Ollama Functions OpenAI Perplexity Perplexity PremAI PromptLayer OpenAI Tencent Hunyuan Together WebLLM xAI YandexGPT ZhipuAI LLMs LLMs AI21 AlephAlpha Arcjet Redact AWS SageMakerEndpoint Azure OpenAI Bedrock ChromeAI Cloudflare Workers AI Cohere Deep Infra Fireworks Friendli Google Vertex AI Gradient AI HuggingFaceInference IBM watsonx.ai JigsawStack Prompt Engine Layerup Security Llama CPP MistralAI NIBittensor Ollama OpenAI PromptLayer OpenAI RaycastAI Replicate Together AI Writer YandexGPT Embedding models Embeddings Alibaba Tongyi Azure OpenAI Baidu Qianfan Amazon Bedrock ByteDance Doubao Cloudflare Workers AI Cohere DeepInfra Fireworks Google Generative AI Google Vertex AI Gradient AI HuggingFace Inference IBM watsonx.ai Jina Llama CPP Minimax MistralAI Mixedbread AI Nomic Ollama OpenAI Pinecone Prem AI Tencent Hunyuan TensorFlow TogetherAI HuggingFace Transformers Voyage AI ZhipuAI Document loaders Vector stores Vector stores AnalyticDB Astra DB Azion EdgeSQL Azion EdgeSQL Azure AI Search Azure Cosmos DB for MongoDB vCore Azure Cosmos DB for NoSQL Cassandra Chroma ClickHouse CloseVector Cloudflare Vectorize Convex Couchbase Elasticsearch Faiss Google Cloud SQL for PostgreSQL Google Cloud SQL for PostgreSQL Google Vertex AI Matching Engine SAP HANA Cloud Vector Engine HNSWLib LanceDB libSQL MariaDB In-memory Milvus Momento Vector Index (MVI) MongoDB Atlas MyScale Neo4j Vector Index Neon Postgres OpenSearch PGVector Pinecone Prisma Qdrant Redis Rockset SingleStore Supabase Tigris Turbopuffer TypeORM Typesense Upstash Vector USearch Vectara Vercel Postgres Voy Weaviate Xata Zep Open Source Zep Cloud Retrievers Retrievers ArxivRetriever Azion EdgeSQL Azion EdgeSQL Knowledge Bases for Amazon Bedrock BM25 Chaindesk Retriever ChatGPT Plugin Retriever Dria Retriever Exa HyDE Retriever Amazon Kendra Retriever Metal Retriever Self-querying retrievers Supabase Hybrid Search Tavily Search API Time-Weighted Retriever Vespa Retriever Zep Cloud Retriever Zep Open Source Retriever Tools/Toolkits Tools and Toolkits ChatGPT Plugins Azure Container Apps Dynamic Sessions Connery Action Tool Dall-E Tool Discord Tool DuckDuckGoSearch ExaSearchResults Gmail Tool Google Calendar Tool Google Places Tool Google Routes Tool Google Scholar Google Trends Tool JigsawStack Tool Agent with AWS Lambda Python interpreter tool SearchApi tool Searxng Search tool SerpAPI StackExchange Tool Stagehand AI Web Automation Toolkit Tavily Search Web Browser Tool Wikipedia tool WolframAlpha Tool Agent with Zapier NLA Integration Toolkits Toolkits Connery Toolkit WatsonxToolkit WatsonxToolkit JSON Agent Toolkit OpenApi Toolkit AWS Step Functions Toolkit Sql Toolkit VectorStore Toolkit Key-value stores Cassandra KV File System Store InMemory Store Key-value stores IORedis Upstash Redis Vercel KV Other Components Chat models Chat models Chat models are language models that use a sequence of messages as inputs and return messages as outputs (as opposed to using plain text). These are generally newer models. info If you'd like to write your own chat model, see this how-to . If you'd like to contribute an integration, see Contributing integrations . Pick your chat model: Groq OpenAI Anthropic FireworksAI MistralAI VertexAI Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/groq yarn add @langchain/groq pnpm add @langchain/groq Add environment variables GROQ_API_KEY = your-api-key Instantiate the model import { ChatGroq } from "@langchain/groq" ; const model = new ChatGroq ( { model : "llama-3.3-70b-versatile" , temperature : 0 } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/openai yarn add @langchain/openai pnpm add @langchain/openai Add environment variables OPENAI_API_KEY = your-api-key Instantiate the model import { ChatOpenAI } from "@langchain/openai" ; const model = new ChatOpenAI ( { model : "gpt-4o-mini" } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/anthropic yarn add @langchain/anthropic pnpm add @langchain/anthropic Add environment variables ANTHROPIC_API_KEY = your-api-key Instantiate the model import { ChatAnthropic } from "@langchain/anthropic" ; const model = new ChatAnthropic ( { model : "claude-3-5-sonnet-20240620" , temperature : 0 } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/community yarn add @langchain/community pnpm add @langchain/community Add environment variables FIREWORKS_API_KEY = your-api-key Instantiate the model import { ChatFireworks } from "@langchain/community/chat_models/fireworks" ; const model = new ChatFireworks ( { model : "accounts/fireworks/models/llama-v3p1-70b-instruct" , temperature : 0 } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/mistralai yarn add @langchain/mistralai pnpm add @langchain/mistralai Add environment variables MISTRAL_API_KEY = your-api-key Instantiate the model import { ChatMistralAI } from "@langchain/mistralai" ; const model = new ChatMistralAI ( { model : "mistral-large-latest" , temperature : 0 } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/google-vertexai yarn add @langchain/google-vertexai pnpm add @langchain/google-vertexai Add environment variables GOOGLE_APPLICATION_CREDENTIALS = credentials.json Instantiate the model import { ChatVertexAI } from "@langchain/google-vertexai" ; const model = new ChatVertexAI ( { model : "gemini-1.5-flash" , temperature : 0 } ) ; await model . invoke ( "Hello, world!" ) Featured providers ‚Äã Model Stream JSON mode Tool Calling withStructuredOutput() Multimodal BedrockChat ‚úÖ ‚ùå üü° (Bedrock Anthropic only) üü° (Bedrock Anthropic only) üü° (Bedrock Anthropic only) ChatBedrockConverse ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚úÖ ChatAnthropic ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚úÖ ChatCloudflareWorkersAI ‚úÖ ‚ùå ‚ùå ‚ùå ‚ùå ChatCohere ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚úÖ ChatFireworks ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatGoogleGenerativeAI ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚úÖ ChatVertexAI ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚úÖ ChatGroq ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatMistralAI ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatOllama ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatOpenAI ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatTogetherAI ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatXAI ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚ùå All chat models ‚Äã Name Description Alibaba Tongyi LangChain.js supports the Alibaba qwen family of models. Anthropic Anthropic is an AI safety and research Arcjet Redact The Arcjet redact integration allows you to redact Azure OpenAI Azure OpenAI is a Microsoft Azure service that provides powerful Baidu Qianfan Setup Amazon Bedrock Amazon Bedrock is a fully managed Amazon Bedrock Converse [Amazon Bedrock Cerebras Cerebras is a model provider that serves open Cloudflare Workers AI Workers AI allows you Cohere Cohere is a Canadian startup that provides Deep Infra LangChain supports chat models hosted by Deep Infra through the ChatD... DeepSeek This will help you getting started with DeepSeek [chat DeepSeek This will help you getting started with DeepSeek [chat Fake LLM LangChain provides a fake LLM chat model for testing purposes. This a... Fireworks Fireworks AI is an AI inference platform to run Friendli Friendli enhances AI application performance and optimizes cost savin... Google GenAI Google AI offers a number of different chat Google Vertex AI Google Vertex is a service that Groq Groq is a company that offers fast AI inference, IBM watsonx.ai This will help you getting started with IBM watsonx.ai [chat Llama CPP Only available on Node.js. Minimax Minimax is a Chinese startup that provides natural language processin... MistralAI Mistral AI is a platform that offers hosting for Moonshot LangChain.js supports the Moonshot AI family of models. Novita AI Delivers an affordable, reliable, and simple inference platform for Ollama Ollama allows you to run open-source large OpenAI OpenAI is an artificial Perplexity This guide will help you getting started with Perplexity [chat Perplexity This guide will help you getting started with Perplexity [chat PremAI Setup Tencent Hunyuan LangChain.js supports the Tencent Hunyuan family of models. Together Together AI offers an API to query [50+ WebLLM Only available in web environments. xAI xAI is an artificial intelligence company that develops YandexGPT LangChain.js supports calling YandexGPT chat models. ZhipuAI LangChain.js supports the Zhipu AI family of models. Was this page helpful? You can also leave detailed feedback on GitHub . Previous Components Next Chat models Community Twitter GitHub Python JS/TS More Homepage Blog Copyright ¬© 2025 LangChain, Inc. Skip to main content Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. Join our team! Integrations API Reference More People Community Error reference External guides Contributing v0.3 v0.3 v0.2 v0.1 ü¶úüîó LangSmith LangSmith Docs LangChain Hub LangServe Python Docs Chat Search Providers Providers Anthropic AWS Google Microsoft OpenAI Components Chat models Chat models Alibaba Tongyi Anthropic Arcjet Redact Azure OpenAI Baidu Qianfan Baidu Wenxin Amazon Bedrock Amazon Bedrock Converse Cerebras Cloudflare Workers AI Cohere Deep Infra DeepSeek DeepSeek Fake LLM Fireworks Friendli Google GenAI Google Vertex AI Groq IBM watsonx.ai Llama CPP Minimax MistralAI Moonshot NIBittensorChatModel Novita AI Ollama Ollama Functions OpenAI Perplexity Perplexity PremAI PromptLayer OpenAI Tencent Hunyuan Together WebLLM xAI YandexGPT ZhipuAI LLMs LLMs AI21 AlephAlpha Arcjet Redact AWS SageMakerEndpoint Azure OpenAI Bedrock ChromeAI Cloudflare Workers AI Cohere Deep Infra Fireworks Friendli Google Vertex AI Gradient AI HuggingFaceInference IBM watsonx.ai JigsawStack Prompt Engine Layerup Security Llama CPP MistralAI NIBittensor Ollama OpenAI PromptLayer OpenAI RaycastAI Replicate Together AI Writer YandexGPT Embedding models Embeddings Alibaba Tongyi Azure OpenAI Baidu Qianfan Amazon Bedrock ByteDance Doubao Cloudflare Workers AI Cohere DeepInfra Fireworks Google Generative AI Google Vertex AI Gradient AI HuggingFace Inference IBM watsonx.ai Jina Llama CPP Minimax MistralAI Mixedbread AI Nomic Ollama OpenAI Pinecone Prem AI Tencent Hunyuan TensorFlow TogetherAI HuggingFace Transformers Voyage AI ZhipuAI Document loaders Vector stores Vector stores AnalyticDB Astra DB Azion EdgeSQL Azion EdgeSQL Azure AI Search Azure Cosmos DB for MongoDB vCore Azure Cosmos DB for NoSQL Cassandra Chroma ClickHouse CloseVector Cloudflare Vectorize Convex Couchbase Elasticsearch Faiss Google Cloud SQL for PostgreSQL Google Cloud SQL for PostgreSQL Google Vertex AI Matching Engine SAP HANA Cloud Vector Engine HNSWLib LanceDB libSQL MariaDB In-memory Milvus Momento Vector Index (MVI) MongoDB Atlas MyScale Neo4j Vector Index Neon Postgres OpenSearch PGVector Pinecone Prisma Qdrant Redis Rockset SingleStore Supabase Tigris Turbopuffer TypeORM Typesense Upstash Vector USearch Vectara Vercel Postgres Voy Weaviate Xata Zep Open Source Zep Cloud Retrievers Retrievers ArxivRetriever Azion EdgeSQL Azion EdgeSQL Knowledge Bases for Amazon Bedrock BM25 Chaindesk Retriever ChatGPT Plugin Retriever Dria Retriever Exa HyDE Retriever Amazon Kendra Retriever Metal Retriever Self-querying retrievers Supabase Hybrid Search Tavily Search API Time-Weighted Retriever Vespa Retriever Zep Cloud Retriever Zep Open Source Retriever Tools/Toolkits Tools and Toolkits ChatGPT Plugins Azure Container Apps Dynamic Sessions Connery Action Tool Dall-E Tool Discord Tool DuckDuckGoSearch ExaSearchResults Gmail Tool Google Calendar Tool Google Places Tool Google Routes Tool Google Scholar Google Trends Tool JigsawStack Tool Agent with AWS Lambda Python interpreter tool SearchApi tool Searxng Search tool SerpAPI StackExchange Tool Stagehand AI Web Automation Toolkit Tavily Search Web Browser Tool Wikipedia tool WolframAlpha Tool Agent with Zapier NLA Integration Toolkits Toolkits Connery Toolkit WatsonxToolkit WatsonxToolkit JSON Agent Toolkit OpenApi Toolkit AWS Step Functions Toolkit Sql Toolkit VectorStore Toolkit Key-value stores Cassandra KV File System Store InMemory Store Key-value stores IORedis Upstash Redis Vercel KV Other Components Chat models Chat models Chat models are language models that use a sequence of messages as inputs and return messages as outputs (as opposed to using plain text). These are generally newer models. info If you'd like to write your own chat model, see this how-to . If you'd like to contribute an integration, see Contributing integrations . Pick your chat model: Groq OpenAI Anthropic FireworksAI MistralAI VertexAI Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/groq yarn add @langchain/groq pnpm add @langchain/groq Add environment variables GROQ_API_KEY = your-api-key Instantiate the model import { ChatGroq } from "@langchain/groq" ; const model = new ChatGroq ( { model : "llama-3.3-70b-versatile" , temperature : 0 } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/openai yarn add @langchain/openai pnpm add @langchain/openai Add environment variables OPENAI_API_KEY = your-api-key Instantiate the model import { ChatOpenAI } from "@langchain/openai" ; const model = new ChatOpenAI ( { model : "gpt-4o-mini" } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/anthropic yarn add @langchain/anthropic pnpm add @langchain/anthropic Add environment variables ANTHROPIC_API_KEY = your-api-key Instantiate the model import { ChatAnthropic } from "@langchain/anthropic" ; const model = new ChatAnthropic ( { model : "claude-3-5-sonnet-20240620" , temperature : 0 } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/community yarn add @langchain/community pnpm add @langchain/community Add environment variables FIREWORKS_API_KEY = your-api-key Instantiate the model import { ChatFireworks } from "@langchain/community/chat_models/fireworks" ; const model = new ChatFireworks ( { model : "accounts/fireworks/models/llama-v3p1-70b-instruct" , temperature : 0 } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/mistralai yarn add @langchain/mistralai pnpm add @langchain/mistralai Add environment variables MISTRAL_API_KEY = your-api-key Instantiate the model import { ChatMistralAI } from "@langchain/mistralai" ; const model = new ChatMistralAI ( { model : "mistral-large-latest" , temperature : 0 } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/google-vertexai yarn add @langchain/google-vertexai pnpm add @langchain/google-vertexai Add environment variables GOOGLE_APPLICATION_CREDENTIALS = credentials.json Instantiate the model import { ChatVertexAI } from "@langchain/google-vertexai" ; const model = new ChatVertexAI ( { model : "gemini-1.5-flash" , temperature : 0 } ) ; await model . invoke ( "Hello, world!" ) Featured providers ‚Äã Model Stream JSON mode Tool Calling withStructuredOutput() Multimodal BedrockChat ‚úÖ ‚ùå üü° (Bedrock Anthropic only) üü° (Bedrock Anthropic only) üü° (Bedrock Anthropic only) ChatBedrockConverse ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚úÖ ChatAnthropic ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚úÖ ChatCloudflareWorkersAI ‚úÖ ‚ùå ‚ùå ‚ùå ‚ùå ChatCohere ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚úÖ ChatFireworks ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatGoogleGenerativeAI ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚úÖ ChatVertexAI ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚úÖ ChatGroq ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatMistralAI ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatOllama ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatOpenAI ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatTogetherAI ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚úÖ ChatXAI ‚úÖ ‚úÖ ‚úÖ ‚úÖ ‚ùå All chat models ‚Äã Name Description Alibaba Tongyi LangChain.js supports the Alibaba qwen family of models. Anthropic Anthropic is an AI safety and research Arcjet Redact The Arcjet redact integration allows you to redact Azure OpenAI Azure OpenAI is a Microsoft Azure service that provides powerful Baidu Qianfan Setup Amazon Bedrock Amazon Bedrock is a fully managed Amazon Bedrock Converse [Amazon Bedrock Cerebras Cerebras is a model provider that serves open Cloudflare Workers AI Workers AI allows you Cohere Cohere is a Canadian startup that provides Deep Infra LangChain supports chat models hosted by Deep Infra through the ChatD... DeepSeek This will help you getting started with DeepSeek [chat DeepSeek This will help you getting started with DeepSeek [chat Fake LLM LangChain provides a fake LLM chat model for testing purposes. This a... Fireworks Fireworks AI is an AI inference platform to run Friendli Friendli enhances AI application performance and optimizes cost savin... Google GenAI Google AI offers a number of different chat Google Vertex AI Google Vertex is a service that Groq Groq is a company that offers fast AI inference, IBM watsonx.ai This will help you getting started with IBM watsonx.ai [chat Llama CPP Only available on Node.js. Minimax Minimax is a Chinese startup that provides natural language processin... MistralAI Mistral AI is a platform that offers hosting for Moonshot LangChain.js supports the Moonshot AI family of models. Novita AI Delivers an affordable, reliable, and simple inference platform for Ollama Ollama allows you to run open-source large OpenAI OpenAI is an artificial Perplexity This guide will help you getting started with Perplexity [chat Perplexity This guide will help you getting started with Perplexity [chat PremAI Setup Tencent Hunyuan LangChain.js supports the Tencent Hunyuan family of models. Together Together AI offers an API to query [50+ WebLLM Only available in web environments. xAI xAI is an artificial intelligence company that develops YandexGPT LangChain.js supports calling YandexGPT chat models. ZhipuAI LangChain.js supports the Zhipu AI family of models. Was this page helpful? You can also leave detailed feedback on GitHub . Previous Components Next Chat models Community Twitter GitHub Python JS/TS More Homepage Blog Copyright ¬© 2025 LangChain, Inc. Skip to main content Skip to main content Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. Join our team! Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. Join our team! Join our team! Providers Providers Anthropic AWS Google Microsoft OpenAI Components Chat models Chat models Alibaba Tongyi Anthropic Arcjet Redact Azure OpenAI Baidu Qianfan Baidu Wenxin Amazon Bedrock Amazon Bedrock Converse Cerebras Cloudflare Workers AI Cohere Deep Infra DeepSeek DeepSeek Fake LLM Fireworks Friendli Google GenAI Google Vertex AI Groq IBM watsonx.ai Llama CPP Minimax MistralAI Moonshot NIBittensorChatModel Novita AI Ollama Ollama Functions OpenAI Perplexity Perplexity PremAI PromptLayer OpenAI Tencent Hunyuan Together WebLLM xAI YandexGPT ZhipuAI LLMs LLMs AI21 AlephAlpha Arcjet Redact AWS SageMakerEndpoint Azure OpenAI Bedrock ChromeAI Cloudflare Workers AI Cohere Deep Infra Fireworks Friendli Google Vertex AI Gradient AI HuggingFaceInference IBM watsonx.ai JigsawStack Prompt Engine Layerup Security Llama CPP MistralAI NIBittensor Ollama OpenAI PromptLayer OpenAI RaycastAI Replicate Together AI Writer YandexGPT Embedding models Embeddings Alibaba Tongyi Azure OpenAI Baidu Qianfan Amazon Bedrock ByteDance Doubao Cloudflare Workers AI Cohere DeepInfra Fireworks Google Generative AI Google Vertex AI Gradient AI HuggingFace Inference IBM watsonx.ai Jina Llama CPP Minimax MistralAI Mixedbread AI Nomic Ollama OpenAI Pinecone Prem AI Tencent Hunyuan TensorFlow TogetherAI HuggingFace Transformers Voyage AI ZhipuAI Document loaders Vector stores Vector stores AnalyticDB Astra DB Azion EdgeSQL Azion EdgeSQL Azure AI Search Azure Cosmos DB for MongoDB vCore Azure Cosmos DB for NoSQL Cassandra Chroma ClickHouse CloseVector Cloudflare Vectorize Convex Couchbase Elasticsearch Faiss Google Cloud SQL for PostgreSQL Google Cloud SQL for PostgreSQL Google Vertex AI Matching Engine SAP HANA Cloud Vector Engine HNSWLib LanceDB libSQL MariaDB In-memory Milvus Momento Vector Index (MVI) MongoDB Atlas MyScale Neo4j Vector Index Neon Postgres OpenSearch PGVector Pinecone Prisma Qdrant Redis Rockset SingleStore Supabase Tigris Turbopuffer TypeORM Typesense Upstash Vector USearch Vectara Vercel Postgres Voy Weaviate Xata Zep Open Source Zep Cloud Retrievers Retrievers ArxivRetriever Azion EdgeSQL Azion EdgeSQL Knowledge Bases for Amazon Bedrock BM25 Chaindesk Retriever ChatGPT Plugin Retriever Dria Retriever Exa HyDE Retriever Amazon Kendra Retriever Metal Retriever Self-querying retrievers Supabase Hybrid Search Tavily Search API Time-Weighted Retriever Vespa Retriever Zep Cloud Retriever Zep Open Source Retriever Tools/Toolkits Tools and Toolkits ChatGPT Plugins Azure Container Apps Dynamic Sessions Connery Action Tool Dall-E Tool Discord Tool DuckDuckGoSearch ExaSearchResults Gmail Tool Google Calendar Tool Google Places Tool Google Routes Tool Google Scholar Google Trends Tool JigsawStack Tool Agent with AWS Lambda Python interpreter tool SearchApi tool Searxng Search tool SerpAPI StackExchange Tool Stagehand AI Web Automation Toolkit Tavily Search Web Browser Tool Wikipedia tool WolframAlpha Tool Agent with Zapier NLA Integration Toolkits Toolkits Connery Toolkit WatsonxToolkit WatsonxToolkit JSON Agent Toolkit OpenApi Toolkit AWS Step Functions Toolkit Sql Toolkit VectorStore Toolkit Key-value stores Cassandra KV File System Store InMemory Store Key-value stores IORedis Upstash Redis Vercel KV Other Components Chat models Chat models Chat models are language models that use a sequence of messages as inputs and return messages as outputs (as opposed to using plain text). These are generally newer models. info If you'd like to write your own chat model, see this how-to . If you'd like to contribute an integration, see Contributing integrations . Pick your chat model: Groq OpenAI Anthropic FireworksAI MistralAI VertexAI Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/groq yarn add @langchain/groq pnpm add @langchain/groq Add environment variables GROQ_API_KEY = your-api-key Instantiate the model import { ChatGroq } from "@langchain/groq" ; const model = new ChatGroq ( { model : "llama-3.3-70b-versatile" , temperature : 0 } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/openai yarn add @langchain/openai pnpm add @langchain/openai Add environment variables OPENAI_API_KEY = your-api-key Instantiate the model import { ChatOpenAI } from "@langchain/openai" ; const model = new ChatOpenAI ( { model : "gpt-4o-mini" } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/anthropic yarn add @langchain/anthropic pnpm add @langchain/anthropic Add environment variables ANTHROPIC_API_KEY = your-api-key Instantiate the model import { ChatAnthropic } from "@langchain/anthropic" ; const model = new ChatAnthropic ( { model : "claude-3-5-sonnet-20240620" , temperature : 0 } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/community yarn add @langchain/community pnpm add @langchain/community Add environment variables FIREWORKS_API_KEY = your-api-key Instantiate the model import { ChatFireworks } from "@langchain/community/chat_models/fireworks" ; const model = new ChatFireworks ( { model : "accounts/fireworks/models/llama-v3p1-70b-instruct" , temperature : 0 } ) ; Install dependencies tip See this section for general instructions on installing integration packages . npm yarn pnpm npm i @langchain/mistralai yarn add @langchain/mistralai pnpm add @langchain/mistralai Add environment variables MISTRAL_API_KEY = your-api-key Instantiate the model import { ChatMistralAI } from "@langchain/mistralai" ; const m

... (content truncated)After exploring the LangChain.js documentation and GitHub repository, I've compiled a comprehensive list of all the available LLM chat model integrations in LangChain.js, including both partner packages and community integrations.
LangChain.js LLM Provider Integrations
Integration Types in LangChain.js
LangChain.js organizes its integrations into two main categories:

Partner Packages: Dedicated packages co-maintained by LangChain and the provider company

Installed via: npm install @langchain/provider-name
Example: @langchain/openai, @langchain/anthropic


Community Integrations: Lighter-weight integrations maintained by the community

Installed via: npm install @langchain/community
Imported from: @langchain/community/chat_models/provider_name



Partner Packages (Dedicated Integrations)
These are maintained in their own dedicated packages and represent the most established and officially supported providers:

OpenAI - @langchain/openai
javascriptimport { ChatOpenAI } from "@langchain/openai";
const model = new ChatOpenAI({ model: "gpt-4o" });

Anthropic - @langchain/anthropic
javascriptimport { ChatAnthropic } from "@langchain/anthropic";
const model = new ChatAnthropic({ model: "claude-3-5-sonnet-20240620" });

Google - @langchain/google-genai (Gemini models)
javascriptimport { ChatGoogleGenerativeAI } from "@langchain/google-genai";
const model = new ChatGoogleGenerativeAI({ model: "gemini-1.5-pro" });

Google Vertex AI - @langchain/google-vertexai
javascriptimport { ChatVertexAI } from "@langchain/google-vertexai";
const model = new ChatVertexAI({ model: "gemini-1.5-flash" });

MistralAI - @langchain/mistralai
javascriptimport { ChatMistralAI } from "@langchain/mistralai";
const model = new ChatMistralAI({ model: "mistral-large-latest" });

Groq - @langchain/groq
javascriptimport { ChatGroq } from "@langchain/groq";
const model = new ChatGroq({ model: "llama-3.3-70b-versatile" });

Azure OpenAI - @langchain/azure-openai
javascriptimport { AzureChatOpenAI } from "@langchain/azure-openai";
const model = new AzureChatOpenAI({
  azureOpenAIApiKey: "your-key",
  azureOpenAIApiVersion: "2024-02-01",
  azureOpenAIApiDeploymentName: "your-deployment",
  azureOpenAIApiInstanceName: "your-instance"
});

Cohere - @langchain/cohere
javascriptimport { ChatCohere } from "@langchain/cohere";
const model = new ChatCohere({ model: "command-r" });

Ollama - @langchain/ollama
javascriptimport { ChatOllama } from "@langchain/ollama";
const model = new ChatOllama({ model: "llama3" });

AWS Bedrock - @langchain/aws
javascriptimport { BedrockChat } from "@langchain/aws";
const model = new BedrockChat({ model: "anthropic.claude-3-sonnet-20240229-v1:0" });

xAI - @langchain/xai
javascriptimport { ChatXAI } from "@langchain/xai";
const model = new ChatXAI({ model: "grok-1" });


Community Integrations
These are available through the @langchain/community package:

Alibaba Tongyi (Qwen models)
javascriptimport { ChatAlibabaTongyi } from "@langchain/community/chat_models/alibaba_tongyi";
const model = new ChatAlibabaTongyi({ model: "qwen-max" });

Arcjet Redact (specialized for redacting sensitive content)
javascriptimport { ChatArcjetRedact } from "@langchain/community/chat_models/arcjet";
const model = new ChatArcjetRedact({ baseModel: baseChatModel });

Baidu Wenxin/ERNIE Bot
javascriptimport { ChatBaiduWenxin } from "@langchain/community/chat_models/baiduwenxin";
const model = new ChatBaiduWenxin({ model: "ernie-bot-4" });

Cloudflare Workers AI
javascriptimport { ChatCloudflareWorkersAI } from "@langchain/community/chat_models/cloudflare_workersai";
const model = new ChatCloudflareWorkersAI({ model: "@cf/meta/llama-3-8b-instruct" });

DeepInfra
javascriptimport { ChatDeepInfra } from "@langchain/community/chat_models/deepinfra";
const model = new ChatDeepInfra({ model: "meta-llama/llama-3-8b-instruct" });

Fireworks AI
javascriptimport { ChatFireworks } from "@langchain/community/chat_models/fireworks";
const model = new ChatFireworks({ model: "accounts/fireworks/models/llama-3-70b-instruct" });

Friendli
javascriptimport { ChatFriendli } from "@langchain/community/chat_models/friendli";
const model = new ChatFriendli({ model: "friendli/nova-8b" });

IBM watsonx.ai
javascriptimport { ChatWatsonx } from "@langchain/community/chat_models/ibm";
const model = new ChatWatsonx({ model: "ibm/granite-20b-chat" });

Llama CPP (local models)
javascriptimport { ChatLlamaCpp } from "@langchain/community/chat_models/llama_cpp";
const model = new ChatLlamaCpp({ modelPath: "./models/llama-3-8b.gguf" });

Minimax
javascriptimport { ChatMinimax } from "@langchain/community/chat_models/minimax";
const model = new ChatMinimax({ model: "abab5.5-chat" });

Moonshot AI
javascriptimport { ChatMoonshot } from "@langchain/community/chat_models/moonshot";
const model = new ChatMoonshot({ model: "moonshot-v1-128k" });

NIBittensor
javascriptimport { NIBittensorChatModel } from "@langchain/community/chat_models/nibittensor";
const model = new NIBittensorChatModel();

Novita AI
javascriptimport { ChatNovita } from "@langchain/community/chat_models/novita";
const model = new ChatNovita({ model: "llama3-8b" });

Perplexity
javascriptimport { ChatPerplexity } from "@langchain/community/chat_models/perplexity";
const model = new ChatPerplexity({ model: "sonar-small-online" });

PremAI
javascriptimport { ChatPremAI } from "@langchain/community/chat_models/premai";
const model = new ChatPremAI({ model: "meta-llama/llama-3-8b-instruct" });

PromptLayer OpenAI (OpenAI with PromptLayer logging)
javascriptimport { PromptLayerChatOpenAI } from "@langchain/community/chat_models/portkey";
const model = new PromptLayerChatOpenAI({ promptLayerApiKey: "pl_..." });

Tencent Hunyuan
javascriptimport { ChatTencentHunyuan } from "@langchain/community/chat_models/tencent_hunyuan";
const model = new ChatTencentHunyuan();

Together AI (access to multiple open models)
javascriptimport { ChatTogetherAI } from "@langchain/community/chat_models/togetherai";
const model = new ChatTogetherAI({ model: "meta-llama/llama-3-70b-instruct" });

WebLLM (browser-based inference)
javascriptimport { ChatWebLLM } from "@langchain/community/chat_models/webllm";
const model = new ChatWebLLM({ modelUrl: "https://example.com/model.gguf" });

YandexGPT
javascriptimport { ChatYandexGPT } from "@langchain/community/chat_models/yandex";
const model = new ChatYandexGPT({ model: "yandexgpt" });

ZhipuAI (GLM models)
javascriptimport { ChatZhipuAI } from "@langchain/community/chat_models/zhipuai";
const model = new ChatZhipuAI({ model: "glm-4" });


Using Multiple Providers Together
You can use multiple providers in the same application by importing their respective packages:
javascriptimport { ChatOpenAI } from "@langchain/openai";
import { ChatAnthropic } from "@langchain/anthropic";
import { ChatMistralAI } from "@langchain/mistralai";
import { ChatFireworks } from "@langchain/community/chat_models/fireworks";

// Initialize different models
const openaiModel = new ChatOpenAI({ model: "gpt-4o" });
const anthropicModel = new ChatAnthropic({ model: "claude-3-5-sonnet-20240620" });
const mistralModel = new ChatMistralAI({ model: "mistral-large-latest" });
const llama3Model = new ChatFireworks({ model: "accounts/fireworks/models/llama-3-70b-instruct" });

